{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d88c152e",
   "metadata": {},
   "source": [
    "# TP01: CleaningData - Applying OOP and Design Patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4bcb29",
   "metadata": {},
   "source": [
    "\n",
    "Each exercise builds upon the previous one - so by the end, we will have a complete CSV cleaning data using OOP, decorators, and patterns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6432bd14",
   "metadata": {},
   "source": [
    "## Exercise 1: Build the CSVReader Class (OOP Foundation)\n",
    "Objective:\n",
    "- Reinforce OOP fundamentals: classes, constructors, methods, encapsulation.\n",
    "- Learn to design reusable data classes for DS projects.\n",
    "Concept:\n",
    "A CSVReader class should encapsulate all functionality related to reading CSV files.\n",
    "\n",
    "Instructions:\n",
    "1.\tCreate a class CSVReader.\n",
    "2.\tDefine an __init__ method that takes file_path.\n",
    "3.\tAdd a read() method that loads the CSV file using pandas.\n",
    "4.\tAdd a preview(n) method that prints the top n rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34012be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name   age  height_cm  weight_kg         city  score\n",
      "0   1    Alice  29.0      165.0       68.0     New York   85.0\n",
      "1   2      Bob   NaN      172.0        NaN  Los Angeles   90.0\n",
      "2   3  Charlie  35.0      168.0       72.0      Chicago    NaN\n",
      "3   4    David   NaN        NaN       80.0      Houston   75.0\n",
      "4   5      Eva  27.0      160.0       55.0     New York   88.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "class CSVReader:\n",
    "    \"\"\" A class to read and preview csv files\"\"\"\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "        self.df = None \n",
    "    def reader(self):\n",
    "        \"\"\" Load csv into self.df and return it.\"\"\"\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "        return self.df\n",
    "    def preview(self,n):\n",
    "        \"\"\"Return top n rows of the dataframe.\"\"\"\n",
    "        if self.df is None:\n",
    "            self.reader()\n",
    "        return self.df.head(n)\n",
    "#Usage \n",
    "csv_reader = CSVReader(\"/Users/macbookair/Documents/Data Science 5th Year/Advanced Programing for DS/Pratice/sample_data.csv\")\n",
    "csv_reader.reader()\n",
    "print(csv_reader.preview(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a915e0ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Load csv into self.df and return it.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "04614fb8",
   "metadata": {},
   "source": [
    "### Exercise 2: Apply Pattern for Missing Values Handling\n",
    "Objective:\n",
    "- Learn the Strategy Pattern - one interface, many interchangeable behaviors.\n",
    "- Practice inheritance and polymorphism.\n",
    "\n",
    "Concept:\n",
    "\n",
    "We often need different strategies to handle missing data (drop, fill mean, fill mode, etc.).\n",
    "The pattern allows flexible switching between methods without changing the main code.\n",
    "\n",
    "Instructions:\n",
    "1.\tCreate an abstract class MissingValueStrategy with a method handle(df).\n",
    "2.\tCreate subclasses:\n",
    "o\tDropMissing\n",
    "o\tFillMean\n",
    "o\tFillMode\n",
    "3.\tCreate a DataCleaner class that applies the chosen strategy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "76bb5d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from abc import ABC, abstractmethod\n",
    "class MissingValueStrategy(ABC):\n",
    "    \"\"\" Strategy class interface for handling missing values \"\"\"\n",
    "    @abstractmethod\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        pass\n",
    "class DropMissing(MissingValueStrategy):\n",
    "    \"\"\" subclass that handles strategy to drop missing values \"\"\"\n",
    "    def handle(self, df:pd.DataFrame):\n",
    "        return df.dropna()\n",
    "\n",
    "class FillMean(MissingValueStrategy):\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        n_cols = df[[\"age\",\"height_cm\",\"weight_kg\",\"score\"]].mean()\n",
    "        return df.fillna(n_cols)\n",
    "\n",
    "class FillMode(MissingValueStrategy):\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        n_cols = df[[\"age\",\"height\",\"weight_kg\",\"score\"]].mode()\n",
    "        return df.fillna(n_cols)\n",
    "\n",
    "class DataCleaner:\n",
    "    \"\"\" Context class that uses a MissingValueStrategy to clean data \"\"\"\n",
    "    def __init__(self,strategy:MissingValueStrategy):\n",
    "        self.strategy = strategy\n",
    "    def clean (self,df):\n",
    "        return self.strategy.handle(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4de9331e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame after Dropping Missing Values:\n",
      "   id   name   age  height_cm  weight_kg      city  score\n",
      "0   1  Alice  29.0      165.0       68.0  New York   85.0\n",
      "4   5    Eva  27.0      160.0       55.0  New York   88.0\n"
     ]
    }
   ],
   "source": [
    "#Example Usage:\n",
    "cleaner = DataCleaner(DropMissing())\n",
    "clean = cleaner.clean(csv_reader.reader())\n",
    "print(\"\\nDataFrame after Dropping Missing Values:\")\n",
    "print(clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce24177",
   "metadata": {},
   "source": [
    "# Exercise 3: Add Decorators for Logging and Timing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6225dd93",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- Learn the Decorator Pattern to add reusable functionality (logging, timing).\n",
    "- Understand how decorators support the “Open/Closed Principle”.\n",
    "\n",
    "Concept:\n",
    "\n",
    "Decorators wrap functions to extend their behavior without altering the original code.\n",
    "Instructions:\n",
    "1.\tCreate two decorators:\n",
    "o\t@log_action → logs when a method starts and finishes.\n",
    "o\t@log_time → calculates and prints execution time.\n",
    "2.\tApply them to methods in CSVReader or DataCleaner.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9350fea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time \n",
    "import logging\n",
    "from functools import wraps\n",
    "import pandas as pd \n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39449ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO) # Configure logging settings \n",
    "# --- Decorators ---\n",
    "def log_action(func):\n",
    "    \"\"\" Logging Decorator \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        logging.info(f\"Starting {func.__name__}\")\n",
    "        result = func(*args, **kwargs)\n",
    "        logging.info(f\"Finished {func.__name__}\")\n",
    "        return result\n",
    "    return wrapper\n",
    "# --- Timing Decorator ---\n",
    "def log_time(func):\n",
    "    \"\"\" Timing Decorator \"\"\"\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"{func.__name__} took {end_time - start_time:.4f} seconds\")\n",
    "        return result\n",
    "    return wrapper\n",
    "class CSVReader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "    @log_action\n",
    "    @log_time\n",
    "    def reader(self):\n",
    "        self.df = pd.read_csv(self.file_path)\n",
    "    def preview(self, n):\n",
    "        self.n = n\n",
    "        return self.df.head(self.n)\n",
    "class MissingValueStrategy(ABC):\n",
    "    @abstractmethod\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        pass\n",
    "class DropMissing(MissingValueStrategy):\n",
    "    def handle(self, df:pd.DataFrame):\n",
    "        return df.dropna()\n",
    "\n",
    "class FillMean(MissingValueStrategy):\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        n_cols = df[[\"age\",\"height_cm\",\"weight_kg\",\"score\"]].mean(numeric_only=True)\n",
    "        return df.fillna(n_cols)\n",
    "\n",
    "class FillMode(MissingValueStrategy):\n",
    "    def handle(self,df:pd.DataFrame):\n",
    "        n_cols = df[[\"age\",\"height\",\"weight_kg\",\"score\"]].mode()\n",
    "        return df.fillna(n_cols)\n",
    "@log_action\n",
    "@log_time\n",
    "class DataCleaner:\n",
    "    def __init__(self,strategy:MissingValueStrategy):\n",
    "        self.strategy = strategy\n",
    "    def clean (self,df):\n",
    "        return self.strategy.handle(df)\n",
    "\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a48298f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting reader\n",
      "INFO:root:reader took 0.0090 seconds\n",
      "INFO:root:Finished reader\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   id     name   age  height_cm  weight_kg         city  score\n",
      "0   1    Alice  29.0      165.0       68.0     New York   85.0\n",
      "1   2      Bob   NaN      172.0        NaN  Los Angeles   90.0\n",
      "2   3  Charlie  35.0      168.0       72.0      Chicago    NaN\n",
      "3   4    David   NaN        NaN       80.0      Houston   75.0\n",
      "4   5      Eva  27.0      160.0       55.0     New York   88.0\n"
     ]
    }
   ],
   "source": [
    "reader = CSVReader(\"/Users/macbookair/Documents/Data Science 5th Year/Advanced Programing for DS/Pratice/sample_data.csv\")\n",
    "df =reader.reader()\n",
    "print(reader.preview(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77bc3803",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting DataCleaner\n",
      "INFO:root:DataCleaner took 0.0000 seconds\n",
      "INFO:root:Finished DataCleaner\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>city</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Alice</td>\n",
       "      <td>29.00</td>\n",
       "      <td>165.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Bob</td>\n",
       "      <td>30.25</td>\n",
       "      <td>172.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>90.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>35.00</td>\n",
       "      <td>168.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>David</td>\n",
       "      <td>30.25</td>\n",
       "      <td>167.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>Houston</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Eva</td>\n",
       "      <td>27.00</td>\n",
       "      <td>160.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>New York</td>\n",
       "      <td>88.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Frank</td>\n",
       "      <td>30.00</td>\n",
       "      <td>175.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Grace</td>\n",
       "      <td>30.25</td>\n",
       "      <td>162.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     name    age  height_cm  weight_kg         city  score\n",
       "0   1    Alice  29.00      165.0       68.0     New York   85.0\n",
       "1   2      Bob  30.25      172.0       70.0  Los Angeles   90.0\n",
       "2   3  Charlie  35.00      168.0       72.0      Chicago   86.0\n",
       "3   4    David  30.25      167.0       80.0      Houston   75.0\n",
       "4   5      Eva  27.00      160.0       55.0     New York   88.0\n",
       "5   6    Frank  30.00      175.0       85.0  Los Angeles   86.0\n",
       "6   7    Grace  30.25      162.0       60.0      Chicago   92.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaner = DataCleaner(FillMean())\n",
    "cleaning = cleaner.clean(reader.df)\n",
    "cleaning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ff9d61",
   "metadata": {},
   "source": [
    "## Exercise 4: Implement Factory Pattern for Data Transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43970858",
   "metadata": {},
   "source": [
    "Objective:\n",
    "\n",
    "- Practice Factory Pattern for scalable creation of transformation objects.\n",
    "- Apply abstraction and composition.\n",
    "\n",
    "Concept:\n",
    "Instead of manually creating objects, use a factory that decides what transformation to apply.\n",
    "\n",
    "Instructions:\n",
    "1.\tCreate an abstract class DataTransform with a method apply(df).\n",
    "2.\tImplement subclasses:\n",
    "o\tNormalizeColumns\n",
    "o\tRemoveDuplicates\n",
    "o\tStandardizeText\n",
    "3.\tCreate a TransformFactory that returns transformation objects based on string input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff323ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataTransform(ABC):\n",
    "    \"\"\" Abstract base class for data transformations \"\"\"\n",
    "    @abstractmethod\n",
    "    def apply(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        pass\n",
    "class NormalizeColumns(DataTransform):\n",
    "    \"\"\" Normalize numeric columns to [0,1] range \"\"\"\n",
    "    def apply(self, df):\n",
    "        numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "        df[numeric_cols] = (df[numeric_cols] - df[numeric_cols].min()) / (df[numeric_cols].max() - df[numeric_cols].min())\n",
    "        return df\n",
    "class RemoveDuplicates(DataTransform):\n",
    "    \"\"\" Remove duplicate rows from the DataFrame \"\"\"\n",
    "    def apply(self, df):\n",
    "        return df.drop_duplicates()\n",
    "    def apply(self, df):\n",
    "        return df.drop_duplicates()\n",
    "class StandardizeText(DataTransform):\n",
    "    \"\"\" Standardize text columns to lowercase and strip whitespace \"\"\"\n",
    "    def apply(self, df):\n",
    "        text_cols = df.select_dtypes(include=['object']).columns\n",
    "        for col in text_cols:\n",
    "            df[col] = df[col].str.lower().str.strip()\n",
    "        return df\n",
    "class TransformationFactory:\n",
    "    \"\"\" Factory class to create data transformation objects \"\"\"\n",
    "    @staticmethod\n",
    "    def create(name, **kwargs):\n",
    "        if name == \"normalize\":\n",
    "            return NormalizeColumns()\n",
    "        elif name == \"remove_duplicates\":\n",
    "            return RemoveDuplicates()\n",
    "        elif name == \"standardize_text\":\n",
    "            return StandardizeText()\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown transformation: {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4690c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>height_cm</th>\n",
       "      <th>weight_kg</th>\n",
       "      <th>city</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>Alice</td>\n",
       "      <td>0.25000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.588235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>Bob</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.882353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>Charlie</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>David</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>Houston</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>Eva</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>New York</td>\n",
       "      <td>0.764706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>Frank</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>0.647059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>Grace</td>\n",
       "      <td>0.40625</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id     name      age  height_cm  weight_kg         city     score\n",
       "0  0.000000    Alice  0.25000   0.333333   0.433333     New York  0.588235\n",
       "1  0.166667      Bob  0.40625   0.800000   0.500000  Los Angeles  0.882353\n",
       "2  0.333333  Charlie  1.00000   0.533333   0.566667      Chicago  0.647059\n",
       "3  0.500000    David  0.40625   0.466667   0.833333      Houston  0.000000\n",
       "4  0.666667      Eva  0.00000   0.000000   0.000000     New York  0.764706\n",
       "5  0.833333    Frank  0.37500   1.000000   1.000000  Los Angeles  0.647059\n",
       "6  1.000000    Grace  0.40625   0.133333   0.166667      Chicago  1.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Example Usage:\n",
    "factory = TransformationFactory()\n",
    "t1 = factory.create(\"normalize\")\n",
    "df_transformed = t1.apply(cleaning)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1152776f",
   "metadata": {},
   "source": [
    "## Exercise 5: Build a Full Cleaning Pipeline (Template Method Pattern)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac62509",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- Combine all previous concepts into one cleaning pipeline.\n",
    "- Use the Template Method Pattern to define a consistent workflow.\n",
    "\n",
    "Concept:\n",
    "The Template Method defines the skeleton of a process and lets subclasses override specific steps.\n",
    "\n",
    "Instructions:\n",
    "1.\tCreate an abstract class DataPipeline with a run() method defining steps:\n",
    "o\tload()\n",
    "o\tclean()\n",
    "o\ttransform()\n",
    "o\tsave()\n",
    "2.\tCreate CSVDataPipeline that implements each step using previous classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8239f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from pathlib import Path\n",
    "from typing import Optional, Union, List, Dict, Any\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# configure logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"[%(asctime)s] %(levelname)s %(message)s\")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ---- Abstract Template ----\n",
    "class DataPipeline(ABC):\n",
    "    \"\"\"\n",
    "    Template Method base class for data pipelines.\n",
    "    Subclasses must implement load(), clean(), transform(), save().\n",
    "    \"\"\"\n",
    "\n",
    "    def run(self, source: Union[str, Path, pd.DataFrame], *, output_path: Optional[Union[str, Path]] = None) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        The template method: orchestrates the full pipeline.\n",
    "        Accepts either a file path (str/Path) or a preloaded DataFrame.\n",
    "        Returns the final cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        logger.info(\"Pipeline started\")\n",
    "        df = self.load(source)\n",
    "        logger.info(\"Loaded data: %s rows, %s cols\", len(df), len(df.columns))\n",
    "        df = self.clean(df)\n",
    "        logger.info(\"After clean: %s rows, %s cols\", len(df), len(df.columns))\n",
    "        df = self.transform(df)\n",
    "        logger.info(\"After transform: %s rows, %s cols\", len(df), len(df.columns))\n",
    "        # optional post-processing hook (subclass may override)\n",
    "        df = self.postprocess(df)\n",
    "        if output_path is not None:\n",
    "            self.save(df, output_path)\n",
    "            logger.info(\"Saved cleaned data to %s\", output_path)\n",
    "        logger.info(\"Pipeline finished\")\n",
    "        return df\n",
    "\n",
    "    @abstractmethod\n",
    "    def load(self, source: Union[str, Path, pd.DataFrame]) -> pd.DataFrame:\n",
    "        \"\"\"Load data from a path or accept a DataFrame directly.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def clean(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply missing-value strategies, type fixes, etc.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Apply transforms (normalize, dedupe, standardize text, etc.).\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @abstractmethod\n",
    "    def save(self, df: pd.DataFrame, output_path: Union[str, Path]) -> None:\n",
    "        \"\"\"Persist the cleaned DataFrame (CSV by default).\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # optional hook\n",
    "    def postprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"Optional final adjustments (override when needed).\"\"\"\n",
    "        return df\n",
    "\n",
    "\n",
    "# ---- CSV implementation that uses previous components ----\n",
    "class CSVDataPipeline(DataPipeline):\n",
    "    \"\"\"\n",
    "    CSVDataPipeline composes:\n",
    "      - a CSVReader (or pandas.read_csv)\n",
    "      - a DataCleaner (strategy-based)\n",
    "      - a TransformFactory to create transforms\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        cleaner,                      # instance of DataCleaner (expects .clean(df) or strategy handle)\n",
    "        transform_configs: Optional[List[Dict[str, Any]]] = None,\n",
    "        reader_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        factory=None                  # TransformFactory instance or None (you can pass class)\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Params:\n",
    "            cleaner: a DataCleaner-like object (has .clean(df) or .strategy.handle)\n",
    "            transform_configs: list of {\"name\": str, \"params\": {...}} applied in order\n",
    "            reader_kwargs: kwargs passed to pd.read_csv when loading from path\n",
    "            factory: TransformFactory instance (must provide .create(name, **params))\n",
    "        \"\"\"\n",
    "        self.cleaner = cleaner\n",
    "        self.transform_configs = transform_configs or []\n",
    "        self.reader_kwargs = reader_kwargs or {}\n",
    "        self.factory = factory\n",
    "\n",
    "    def load(self, source: Union[str, Path, pd.DataFrame]) -> pd.DataFrame:\n",
    "        # Accept a DataFrame directly\n",
    "        if isinstance(source, pd.DataFrame):\n",
    "            logger.info(\"Source is a DataFrame, copying to avoid mutation.\")\n",
    "            return source.copy()\n",
    "        # Accept a path-like (string or Path)\n",
    "        path = Path(source)\n",
    "        if not path.exists():\n",
    "            raise FileNotFoundError(f\"Input file not found: {path}\")\n",
    "        # Use pandas directly or your CSVReader wrapper\n",
    "        df = pd.read_csv(path, **self.reader_kwargs)\n",
    "        return df\n",
    "\n",
    "    def clean(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Use the injected cleaner. Two common interfaces:\n",
    "        - cleaner.clean(df) -> DataFrame\n",
    "        - cleaner.strategy.handle(df) -> DataFrame\n",
    "        The code below tries to support either.\n",
    "        \"\"\"\n",
    "        if hasattr(self.cleaner, \"clean\"):\n",
    "            return self.cleaner.clean(df)\n",
    "        elif hasattr(self.cleaner, \"strategy\") and hasattr(self.cleaner.strategy, \"handle\"):\n",
    "            return self.cleaner.strategy.handle(df)\n",
    "        else:\n",
    "            raise AttributeError(\"Cleaner must provide .clean(df) or .strategy.handle(df)\")\n",
    "\n",
    "    def transform(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Apply a list of transform configs (each config = {\"name\": str, \"params\": {...}}).\n",
    "        The factory must implement create(name, **params) -> DataTransform.\n",
    "        \"\"\"\n",
    "        out = df.copy()\n",
    "        if not self.transform_configs:\n",
    "            return out\n",
    "\n",
    "        if self.factory is None:\n",
    "            raise RuntimeError(\"TransformFactory instance not provided to CSVDataPipeline\")\n",
    "\n",
    "        for conf in self.transform_configs:\n",
    "            name = conf.get(\"name\")\n",
    "            params = conf.get(\"params\", {})\n",
    "            logger.info(\"Applying transform %s with params %s\", name, params)\n",
    "            transform_obj = self.factory.create(name, **params)  # must return DataTransform\n",
    "            out = transform_obj.apply(out)\n",
    "        return out\n",
    "\n",
    "    def save(self, df: pd.DataFrame, output_path: Union[str, Path]) -> None:\n",
    "        p = Path(output_path)\n",
    "        p.parent.mkdir(parents=True, exist_ok=True)\n",
    "        df.to_csv(p, index=False)\n",
    "\n",
    "    # Optional override for the final step\n",
    "    def postprocess(self, df: pd.DataFrame) -> pd.DataFrame:\n",
    "        # example: reset index, enforce dtypes, drop temporary cols\n",
    "        return df.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f391bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Pipeline started\n",
      "INFO:__main__:Source is a DataFrame, copying to avoid mutation.\n",
      "INFO:__main__:Loaded data: 3 rows, 2 cols\n",
      "/var/folders/kd/y4dd_m917sjclbk19n2xcbjr0000gn/T/ipykernel_58811/3170224063.py:4: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  def clean(self, df): return df.fillna(method=\"ffill\").copy()\n",
      "INFO:__main__:After clean: 3 rows, 2 cols\n",
      "INFO:__main__:Applying transform identity with params {}\n",
      "INFO:__main__:After transform: 3 rows, 2 cols\n",
      "INFO:__main__:Pipeline finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A     name\n",
      "0  1.0    Alice\n",
      "1  1.0    Alice\n",
      "2  3.0  Charlie\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ---- Example usage ----\n",
    "if __name__ == \"__main__\":\n",
    "    class SimpleCleaner:\n",
    "        def clean(self, df): return df.fillna(method=\"ffill\").copy()\n",
    "\n",
    "    class DummyFactory:\n",
    "        def create(self, name, **params):\n",
    "            # Minimal transform object with apply(df) method\n",
    "            class IdentityTransform:\n",
    "                def apply(self, df): return df\n",
    "            return IdentityTransform()\n",
    "\n",
    "    cleaner = SimpleCleaner()\n",
    "    factory = DummyFactory()\n",
    "    transforms = [{\"name\": \"identity\"}]\n",
    "\n",
    "    pipeline = CSVDataPipeline(cleaner=cleaner, transform_configs=transforms, factory=factory)\n",
    "    # pass either a path or DataFrame:\n",
    "    sample_df = pd.DataFrame({\"A\":[1, None, 3], \"name\":[\"Alice\", None, \"Charlie\"]})\n",
    "    result = pipeline.run(sample_df, output_path=None)   # returns final DataFrame\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38effad4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.11.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
